\chapter{Introduction}
\label{introduction}

%% XXX consistent capitalisation of Mock Object and other Test Pattern names

This dissertation will explore the use of a unit testing technique
called the ``Mock Object Pattern'' in the strongly, statically typed
functional programming language OCaml. Mocking (or object mocking, as
it is more commonly known) is method of replacing hard-to-test
dependencies in object-oriented code with automatically generated
objects in order to make it easier to write unit tests. The technique
was first applied for use in Java, which is an object oriented
language with static types and run-time instrumentation facilities.

%% This disertation will describe the current state-of-the-art in unit
%% testing, specifically as it applies to functional programming
%% languages similar to OCaml (XXX just cover the thesis' organisation
%% here).

The dissertation is organised as follows. Chapter \ref{introduction},
Introduction, briefly describes the topic of software testing and
introduces the topic of Mock Objects. Chapter \ref{background},
Background, describes software testing in more detail, including
different levels of testing, common test design patterns, and tools
commonly used for testing. Chapter \ref{application}, Application,
describes the implementation of a tool, MoCaml, to assist OCaml
developers in automatically generating mock dependencies, and compares
tests written using this tool versus other similar tools. Chapter
\ref{reflection}, Reflection, describes the experience of writing
tests using MoCaml to write tests.

\section{Motivation of this dissertation}

%% We want to show why it is important to test software

%% Why is testing important? Include the statistic about how expensive
%% bugs are to fix after code has been shipped.

\subsection{Why write unit tests}

Automated testing is an important part of software development. At its
most basic, software testing is a means of demonstrating the quality
of software -- and the costs of poor quality in software can be
huge. In 2002, the US National Institute of Standards and Technology
estimated that poor software testing practices may cost the US between
\$22.2 and \$59.5 billion USD per year (not including the costs of
``mission critical'' software whose failure could lead to catastrophic
failure or loss of life). Furthermore, studies have shown that the
cost of fixing a software defect in production may be up to two orders
of magnitude greater than if the bug had been fixed in the development
phase. \cite{mcconnell:code} \cite{boehm:understanding} While this
``orders of magnitude'' statement has been part of the software
engineering lore since Boehm first made the observation in 1988, more
recent analysis \cite{boehm:software} \cite{bossavit:leprechauns}
indicates that the ratio of cost between fixing a bug in development
versus production may be closer to 1:5 rather than
1:100. Nevertheless, this is still a strong motivation to resolve
software defects as early as possible in the development cycle.



% testing versus static type checking



%% Much of the below is lifted from the proposal. I need to chop out
%% some stuff that's not necessary here, and beef up the parts that
%% are.

% types of tests. probably don't need this?

Software tests are typically grouped into three different levels:
system tests, component tests, and unit tests \cite{XXX}. These %% should I cite humble here? who talk s about system and component tests?
categories represent a spectrum of granularity. Systems tests
represent the broadest granularity, and are meant to test the entire
system as a whole. On the other end of the spectrum are unit tests,
which test functionality at the finest level of granularity: typically
a method or function. Component tests sit somewhere in between the two
ends of the spectrum, and might test interactions between modules or
classes of an application, or perhaps the interaction between distinct
services of a larger application. Some textbooks, particularly those
describing Agile software development practices, prefer the terms
acceptance and integration tests over system and component tests
\cite{freeman:growing} \cite{humble:continuous}. While these terms are
perhaps more descriptive of the objective of the different types of
tests, in this dissertation we will prefer to use the terms system and
component test, which better demonstrate {\em what} is being tested.

Recent trends in Agile development, such as continuous integration
\cite{humble:continuous} and test driven development \cite{beck:tdd},
have placed a greater emphasis on unit testing. Consequentially, many
tools and libraries have been developed to assist programmers in
writing these tests. Many of these libraries, such as JUnit
\cite{www:junit} for Java, NUnit \cite{www:nunit} for .NET, Test:Unit
\cite{www:ruby:unit} and RSpec \cite{www:rspec} for Ruby, and OUnit
\cite{www:ounit} for OCaml, follow the xUnit patterns of test
development described by Meszaros \cite{meszaros:xunit}. This family
of libraries typically provides a set of convenient assertion
functions to help the user write test cases, annotations to help
organise these test cases into larger test suites, and test harnesses
to handle test running and status reporting.

%\subsection{What are Mocks}
\subsection{Unit testing terms}

%% Describe xUnit pattern component names

%% XXX This might be a better fit for the Background section. Perhaps
%% we want a smaller introduction to Mocks in the Intro?

To understand mock objects, we should first familiarise ourselves with
the xUnit Pattern Language \cite{meszaros:xunit}. A pattern language
is a high-level, often visual, framework for describing patterns that
occur in software engineering. The xUnit Pattern Language has a
vocabulary that aids in describing the patterns that commonly occur
in unit testing. Primarily, it contains a vocabulary that covers most
aspects of software engineering and software testing. The following is
glossary of terms we will use in the following chapters.

\begin{description}

\item[System Under Test (SUT)] The part of the software that is being
  tested. Confusingly, this doesn't necessarily refer to the system as
  a whole, but rather the component of the system that is actually
  being tested. For instance, if we are testing a particular HTTP
  handler of a web application, the SUT is the HTTP handler itself,
  not the web application as a whole.

\item[Depended-On Component (DOC)] A component of the software which
  is a required dependency of the SUT. For instance, the HTTP handler
  we are testing may make a database query through an object
  relational mapper (ORM). In this case, the ORM is a DOC. A SUT may
  have more than one DOC.

\item[Dependency Injection (DI)] The act of configuring a SUT's
  dependencies, either at compile-time or run-time. A dependency which
  is configured at compile-time is often described as a ``hard-coded''
  dependency. Various dependency injection frameworks exist which
  provide facilities for configuring dependencies at run-time. For
  instance, a DI framework might instruct the ORM to map to a test
  database when a program is run in test mode, but would map to the
  real database when the program is run in production. This prevents
  the components of the software which interact with the database
  through the ORM from having to handle special-cases for testing
  purposes.\footnote{Dependency injection is not necessarily a part
    of the xUnit Pattern Language, but it is defined here because
    dependency injection plays an important role in the construction
    of tests that use the mocking technique.}

% p. 209
\item[Hard-to-Test Code] For many reasons, some software components
  will be hard to test. A component may depend on external data that
  isn't available at test time. A component may require certain
  specialised hardware to run which isn't available at test time. A
  component may be difficult to access programmatically (such as a GUI
  or web interface). Or the software may be written in a way that will
  make tests brittle and prone to breaking (such is the case with
  tightly coupled components). Refactoring may help make tightly
  coupled code easier to test, but some components may just be
  intrinsically hard to test.

% p. 59
\item[Test fixture] Tests often require certain infrastructure to be
  set up prior to a test run. A test database may need to be
  instantiated, or the program may need to be guided into a certain
  state before a particular test is run. The component which handles
  setting up this infrastructure is known as the test fixture
  (sometimes referred to as a test harness). Test fixtures often use
  a form of dependency injection to set up tests.

%% is this definition necessary?
%% \item[Test suite] A collection of tests which are meant to be run
%%   together.

%% Are we spilling the beans to early here?
\item[Test double] It may be impossible to test the SUT because it
  contains a DOC which is hard-to-test. In this case, the test double
  pattern can be used. A test double is a replacement for a
  hart-to-test DOC which makes it possible to test the SUT. xUnit
  defines the following test doubles: Test Stub, Test Spy, Mock
  Object, and Fake Object. In addition to these types of double, test
  doubles may either be configurable at run time, or have their
  configuration hard-coded. Test doubles will be further discussed in
  section \ref{testdoubles}, where we will discuss the mock pattern in
  much greater depth.

\end{description}

xUnit Test Patterns also defines the four phases of the testing life cycle:

\begin{enumerate}

\item \textbf{Setup} Initialise the required state so that the unit
  test is ready to be run. Depending on the test case, this may
  involve starting an http server, initiating a connection to a
  database and loading test data, or simply creating a test double and
  injecting it into the SUT. The point here is to provide context for
  the SUT to be executed.

\item \textbf{Exercise} This step simply executes the SUT in question
  within the context provided by the setup phase.

\item \textbf{Verify} Determine whether the test passed or failed by
  comparing the results of the execution phase to the expected
  results. This is typically accomplished by calling an \code{assert}
  function provided by the unit test framework being used, although it
  could be a more complext step such as verifying new database
  records, or calling a mock object's verification
  method.%% \footnote{Mocks will be covered in greater detail in section
    %% \ref{testdoubles:mocks}}

\item \textbf{Teardown} Cleanup after the test has finished. This
  involves undoing anything that was done in the setup phase, and
  perhas cleaning up any unwanted output generated by the SUT in the
  exercise phase, such as log files, etc.

\end{enumerate}

\section{Test doubles and the mock pattern}

For various reasons, some code is just hard to test. Often this
manifests itself in the form of hard-to-test dependencies of the
SUT. Examples of these DOCs may include queries to databases,
side-effecting code that is infeasible to run in a test environment,
or, as in the case of Test-Driven Development \cite{beck:tdd}, we are
testing a SUT which has a DOC that has not yet been fully implemented.

A SUT may be hard to test not only because of a hard-to-test DOC, but
because it is difficult to verify that the SUT has interacted with the
DOC in an appropriate way. For instance, we may want to test that the
SUT has sanitised its inputs before calling out to the ORM, but to do
so would require intercepting calls to the ORM, or modifying the ORM
specifically for the test case. The solution to this type of testing
problem is known as Behaviour Verification \cite{meszaros:xunit}.

The Test Double Pattern is a solution to the hard-to-test DOC
problem. A test double is an implementation of the DOC's interface
which can be used as a drop-in replacement for the DOC, thereby making
the SUT easier to test. Test doubles come in five flavours: Dummy
Objects, Test Stubs, Test Spies, Mock Objects, and Fake Objects. While
each of these types of test double can be used in place of a
hard-to-test DOC, each has a specific purpose that makes it better
suited for particular applications.

A Mock Object has unique capabilities that distinguish it from the
other test double patterns. A Mock Object implementes the interface
which we wish to replace, but allows the programmer to specify the
expected behaviour of the Mock during the test. These expectations may
specify both the expected inputs to a mocked method, as well as its
expected outputs. Mock Objects provide a verification method which
allows the test case to verify that the SUT interacted with the Mock
Object in the expected way. Mock Objects are also typically
automatically generated by the testing framework, and therefore are
considered to be dynamically configured test doubles. Because of these
properties, Mock Objects are very well suited for performing Behaviour
Verification.

\section{Current implementations of the Mock Object Pattern}

As implied by its name, the Mock Object pattern is a technique that
originated from the Object Oriented programming language
community. One of the first tools implemented to assist programmers in
writing Mock Objects was JMock \cite{www:jmock} for the Java
programming language. Mocking frameworks for other Object Oriented
languages exist as well, such as Moq \cite{www:moq} for C# and .NET,
and RSpec \cite{www:rspec} for Ruby. These mocking frameworks each
support the automatic generation of mock implementations of objects
through the use of run-time reflection and code generation.

%% XXX need to double check the implemenetation of these libraries!

Reflection is a language feature which allows programs to perform
introspection at run time. In the case of mocking frameworks,
reflection is used to inspect a given class type (in Java's JMock and
.NET's Moq) or object (in the case of Ruby's RSpec) and generate an
object which implements the same interface as the orignal class type
or object. The framework provides functions for overriding the methods
of this generated object with user-provided expectations. The new
object can be used in place of the DOC in the SUT, and after the test
has executed, the mock's expectations can be verified.

Currently there is no implemetation of a dynaamically configurable
mock framework for OCaml that automatically generates mock
implementations of interfaces. The closest OCaml library for
implementing the Mock Object pattern is Xavier Clerc's Kaputt unit
testing tool \cite{www:kaputt}, which provides function combinators
for assisting programmers in writing hard-coded mock implementations
of functions. Compared to the dynamically configurable mocks generated
by the likes of JMock and RSpec, this is quite
cumbersome. Furthermore, the library only provides facilities for
mocking individual functions, meaning that if the user wants to write
a mock implementation of an entire module or object, then the user
must implement the entire interface manually, rather than just
providing expectations for the few functions exercised by the test
case.

Although it has neither run-time reflection nor run-time code
generation\footnote{While OCaml has execellent code generation
  facilities in the form of the \code{compiler-libs} library, it
  cannot generate at run-time code which could be executed by the same
  run-time environment.} capabilities, OCaml still has the potential
to host a dynamically configurable mocking framework, which could
fully implement a mock of a given interface and allow a programmer to
provide verifiable expectations for that mock. Among its many
benefits, OCaml has two important features we need: a strong, static
type system, and a powerful preprocessor and code generation facility
called camlp4 \cite{www:camlp4}. These two features will allow us to
write a fully-featured, dynamically configurable mocking framework for
OCaml.

\section{Objectives and expected contribution}

The objective of this dissertation is to create a dynamically
configurable mocking framework for OCaml, and to describe in detail
both its implementation and evaluate its use as a testing tool, in
comparison with mocking frameworks for other languages (both object
oriented and functional), and in comparison with other testing tools
for OCaml. In the background section, we will cover software testing
theory in more detail, and fully describe the Test Double patterns and
their use and implementation. In addition, we will discuss the OCaml
language, and explain how its features aid and hinder the
implementation of a mocking framework. Finally, we will discuss the
usefullness of the Mock Object pattern in a functional langauge
compared with its usefullness in an object oriented langauge.
